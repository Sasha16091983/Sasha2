{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аналіз даних за допомогою методів машинного навчання\n",
    "\n",
    "У цьому ноутбуці ми проведемо аналіз даних за допомогою методів машинного навчання, включаючи регресійний аналіз, класифікацію та оптимізацію моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Допоміжні функції\n",
    "\n",
    "Спочатку визначимо допоміжні функції для оцінки моделей регресії та класифікації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для виведення результатів регресії\n",
    "def print_regression_metrics(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\nМетрики для {model_name}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    return mae, mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для виведення результатів класифікації\n",
    "def print_classification_metrics(y_true, y_pred, model_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nМетрики для {model_name}:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"\\nДетальний звіт:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 1: Регресійний аналіз\n",
    "\n",
    "У цьому розділі ми проведемо регресійний аналіз даних, використовуючи лінійну регресію та Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ЗАВДАННЯ 1: РЕГРЕСІЙНИЙ АНАЛІЗ =====\n",
      "\n",
      "Перші 5 рядків даних для регресії:\n",
      "   feature_1  feature_2  feature_3  feature_4  feature_5 category      target\n",
      "0  -0.441624   0.056910   2.145108   0.545351  -1.000692        B  158.228802\n",
      "1   0.267580  -0.866764   0.307010   0.180572  -2.300686        C  -41.069085\n",
      "2  -0.546059   0.587494  -0.179630   0.913220   0.542977        C   32.716057\n",
      "3  -0.104489   0.252424   0.477136   0.745406  -0.954770        C   32.369672\n",
      "4   0.951492  -0.102303   0.862357  -0.023328  -0.613082        A   88.818761\n",
      "\n",
      "Інформація про дані:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature_1  1000 non-null   float64\n",
      " 1   feature_2  1000 non-null   float64\n",
      " 2   feature_3  1000 non-null   float64\n",
      " 3   feature_4  1000 non-null   float64\n",
      " 4   feature_5  1000 non-null   float64\n",
      " 5   category   1000 non-null   object \n",
      " 6   target     1000 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "\n",
      "Статистика даних:\n",
      "         feature_1    feature_2    feature_3    feature_4    feature_5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean     -0.033809    -0.019503     0.033488     0.025743    -0.070029   \n",
      "std       1.000976     0.981986     1.028637     1.024685     1.044944   \n",
      "min      -3.154552    -3.197773    -3.223793    -3.371200    -3.371959   \n",
      "25%      -0.722583    -0.691455    -0.663353    -0.650234    -0.774138   \n",
      "50%      -0.012494     0.006123     0.067062     0.067450    -0.074169   \n",
      "75%       0.652875     0.646668     0.715580     0.692349     0.630069   \n",
      "max       2.808930     2.861424     3.763371     2.697397     3.046338   \n",
      "\n",
      "            target  \n",
      "count  1000.000000  \n",
      "mean     -1.122326  \n",
      "std     124.745792  \n",
      "min    -394.413627  \n",
      "25%     -81.684936  \n",
      "50%      -0.770371  \n",
      "75%      83.282659  \n",
      "max     400.065294  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== ЗАВДАННЯ 1: РЕГРЕСІЙНИЙ АНАЛІЗ =====\\n\")\n",
    "\n",
    "# Завантаження даних для регресії\n",
    "regression_data = pd.read_csv('variant_14_regression.csv')\n",
    "print(\"Перші 5 рядків даних для регресії:\")\n",
    "print(regression_data.head())\n",
    "print(\"\\nІнформація про дані:\")\n",
    "print(regression_data.info())\n",
    "print(\"\\nСтатистика даних:\")\n",
    "print(regression_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Кількість пропущених значень:\n",
      "feature_1    0\n",
      "feature_2    0\n",
      "feature_3    0\n",
      "feature_4    0\n",
      "feature_5    0\n",
      "category     0\n",
      "target       0\n",
      "dtype: int64\n",
      "\n",
      "Категоріальні ознаки: ['category']\n",
      "Числові ознаки: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5']\n"
     ]
    }
   ],
   "source": [
    "# Перевірка пропущених значень\n",
    "print(\"\\nКількість пропущених значень:\")\n",
    "print(regression_data.isnull().sum())\n",
    "\n",
    "# Визначення категоріальних і числових ознак\n",
    "reg_categorical_cols = regression_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "reg_numerical_cols = regression_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "reg_numerical_cols.remove('target')  # Видаляємо цільову змінну зі списку ознак\n",
    "\n",
    "print(f\"\\nКатегоріальні ознаки: {reg_categorical_cols}\")\n",
    "print(f\"Числові ознаки: {reg_numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підготовка даних для регресії\n",
    "X_reg = regression_data.drop('target', axis=1)\n",
    "y_reg = regression_data['target']\n",
    "\n",
    "# Створення препроцесора для регресії\n",
    "reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), reg_numerical_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), reg_categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Розділення даних на тренувальну та тестову вибірки\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лінійна регресія\n",
    "linear_reg = Pipeline([\n",
    "    ('preprocessor', reg_preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_reg.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred_linear = linear_reg.predict(X_reg_test)\n",
    "\n",
    "# Random Forest регресія\n",
    "rf_reg = Pipeline([\n",
    "    ('preprocessor', reg_preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "rf_reg.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred_rf = rf_reg.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики для Лінійна регресія:\n",
      "MAE: 16.7277\n",
      "MSE: 432.2413\n",
      "R²: 0.9767\n",
      "\n",
      "Метрики для Random Forest регресія:\n",
      "MAE: 27.7116\n",
      "MSE: 1293.4527\n",
      "R²: 0.9303\n",
      "\n",
      "Порівняння моделей регресії:\n",
      "Лінійна регресія показує кращі результати.\n",
      "Причини: Дані можуть мати лінійну структуру або містити мало ознак.\n"
     ]
    }
   ],
   "source": [
    "# Оцінка моделей регресії\n",
    "linear_metrics = print_regression_metrics(y_reg_test, y_reg_pred_linear, \"Лінійна регресія\")\n",
    "rf_metrics = print_regression_metrics(y_reg_test, y_reg_pred_rf, \"Random Forest регресія\")\n",
    "\n",
    "# Порівняння моделей регресії\n",
    "print(\"\\nПорівняння моделей регресії:\")\n",
    "if rf_metrics[2] > linear_metrics[2]:\n",
    "    print(\"Random Forest регресія показує кращі результати.\")\n",
    "    print(\"Причини: Random Forest може моделювати нелінійні залежності та взаємодії між ознаками.\")\n",
    "else:\n",
    "    print(\"Лінійна регресія показує кращі результати.\")\n",
    "    print(\"Причини: Дані можуть мати лінійну структуру або містити мало ознак.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 2: Класифікація\n",
    "\n",
    "У цьому розділі ми проведемо класифікацію даних, використовуючи логістичну регресію та Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== ЗАВДАННЯ 2: КЛАСИФІКАЦІЯ =====\n",
      "\n",
      "Перші 5 рядків даних для класифікації:\n",
      "   feature_1  feature_2  feature_3  feature_4  feature_5 category  target\n",
      "0   1.144100   1.365056  -0.492980  -0.052019  -1.774204        A       1\n",
      "1   0.081634  -3.275986  -2.840944  -1.196610   1.443525        C       0\n",
      "2  -0.340361  -2.645979  -0.643340  -0.600262   1.984598        A       0\n",
      "3  -0.990415   1.814362  -2.060027  -4.380028   2.878635        A       0\n",
      "4  -0.923337  -1.700510  -0.032281   0.193580  -2.142717        A       1\n",
      "\n",
      "Інформація про дані:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature_1  1000 non-null   float64\n",
      " 1   feature_2  1000 non-null   float64\n",
      " 2   feature_3  1000 non-null   float64\n",
      " 3   feature_4  1000 non-null   float64\n",
      " 4   feature_5  1000 non-null   float64\n",
      " 5   category   1000 non-null   object \n",
      " 6   target     1000 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "\n",
      "Статистика даних:\n",
      "         feature_1    feature_2    feature_3    feature_4    feature_5  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.524940    -0.525590     0.458157     0.060448     0.578380   \n",
      "std       1.381812     1.621195     1.561357     1.633654     1.617132   \n",
      "min      -5.299612    -5.103506    -4.585490    -5.508850    -4.411686   \n",
      "25%      -0.228770    -1.632819    -0.656671    -1.057127    -0.484866   \n",
      "50%       0.675344    -0.650241     0.468566     0.180417     0.609321   \n",
      "75%       1.450080     0.540325     1.564075     1.161703     1.704055   \n",
      "max       4.434926     5.463142     6.474060     4.819970     5.796755   \n",
      "\n",
      "            target  \n",
      "count  1000.000000  \n",
      "mean      0.501000  \n",
      "std       0.500249  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       1.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n===== ЗАВДАННЯ 2: КЛАСИФІКАЦІЯ =====\\n\")\n",
    "\n",
    "# Завантаження даних для класифікації\n",
    "classification_data = pd.read_csv('variant_14_classification.csv')\n",
    "print(\"Перші 5 рядків даних для класифікації:\")\n",
    "print(classification_data.head())\n",
    "print(\"\\nІнформація про дані:\")\n",
    "print(classification_data.info())\n",
    "print(\"\\nСтатистика даних:\")\n",
    "print(classification_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Кількість пропущених значень:\n",
      "feature_1    0\n",
      "feature_2    0\n",
      "feature_3    0\n",
      "feature_4    0\n",
      "feature_5    0\n",
      "category     0\n",
      "target       0\n",
      "dtype: int64\n",
      "\n",
      "Категоріальні ознаки: ['category']\n",
      "Числові ознаки: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5']\n"
     ]
    }
   ],
   "source": [
    "# Перевірка пропущених значень\n",
    "print(\"\\nКількість пропущених значень:\")\n",
    "print(classification_data.isnull().sum())\n",
    "\n",
    "# Визначення категоріальних і числових ознак\n",
    "cls_categorical_cols = classification_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "cls_numerical_cols = classification_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cls_numerical_cols.remove('target')  # Видаляємо цільову змінну зі списку ознак\n",
    "\n",
    "print(f\"\\nКатегоріальні ознаки: {cls_categorical_cols}\")\n",
    "print(f\"Числові ознаки: {cls_numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підготовка даних для класифікації\n",
    "X_cls = classification_data.drop('target', axis=1)\n",
    "y_cls = classification_data['target']\n",
    "\n",
    "# Створення препроцесора для класифікації\n",
    "cls_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), cls_numerical_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), cls_categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Розділення даних на тренувальну та тестову вибірки\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логістична регресія\n",
    "logistic_cls = Pipeline([\n",
    "    ('preprocessor', cls_preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "logistic_cls.fit(X_cls_train, y_cls_train)\n",
    "y_cls_pred_logistic = logistic_cls.predict(X_cls_test)\n",
    "\n",
    "# Random Forest класифікація\n",
    "rf_cls = Pipeline([\n",
    "    ('preprocessor', cls_preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_cls.fit(X_cls_train, y_cls_train)\n",
    "y_cls_pred_rf = rf_cls.predict(X_cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики для Логістична регресія:\n",
      "Accuracy: 0.7300\n",
      "\n",
      "Детальний звіт:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       101\n",
      "           1       0.70      0.80      0.75        99\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.73      0.73       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n",
      "\n",
      "Метрики для Random Forest класифікація:\n",
      "Accuracy: 0.9150\n",
      "\n",
      "Детальний звіт:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       101\n",
      "           1       0.93      0.90      0.91        99\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.91      0.91       200\n",
      "weighted avg       0.92      0.92      0.91       200\n",
      "\n",
      "\n",
      "Порівняння моделей класифікації:\n",
      "Random Forest класифікація показує кращі результати.\n",
      "Причини: Random Forest може краще моделювати складні взаємодії між ознаками.\n"
     ]
    }
   ],
   "source": [
    "# Оцінка моделей класифікації\n",
    "logistic_acc = print_classification_metrics(y_cls_test, y_cls_pred_logistic, \"Логістична регресія\")\n",
    "rf_acc = print_classification_metrics(y_cls_test, y_cls_pred_rf, \"Random Forest класифікація\")\n",
    "\n",
    "# Порівняння моделей класифікації\n",
    "print(\"\\nПорівняння моделей класифікації:\")\n",
    "if rf_acc > logistic_acc:\n",
    "    print(\"Random Forest класифікація показує кращі результати.\")\n",
    "    print(\"Причини: Random Forest може краще моделювати складні взаємодії між ознаками.\")\n",
    "else:\n",
    "    print(\"Логістична регресія показує кращі результати.\")\n",
    "    print(\"Причини: Дані можуть мати просту структуру або містити мало ознак.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 3: Оптимізація моделі\n",
    "\n",
    "У цьому розділі ми оптимізуємо модель, яка показала кращі результати (регресія або класифікація)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== ЗАВДАННЯ 3: ОПТИМІЗАЦІЯ МОДЕЛІ =====\n",
      "\n",
      "Оптимізуємо Random Forest Classifier, оскільки він показав кращі результати.\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Найкращі параметри:\n",
      "{'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "\n",
      "Результати до оптимізації:\n",
      "Accuracy: 0.9150\n",
      "\n",
      "Результати після оптимізації:\n",
      "\n",
      "Метрики для Оптимізований Random Forest Classifier:\n",
      "Accuracy: 0.9150\n",
      "\n",
      "Детальний звіт:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92       101\n",
      "           1       0.93      0.90      0.91        99\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.91      0.91       200\n",
      "weighted avg       0.92      0.92      0.91       200\n",
      "\n",
      "\n",
      "Покращення після оптимізації:\n",
      "Accuracy: 0.0000 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n===== ЗАВДАННЯ 3: ОПТИМІЗАЦІЯ МОДЕЛІ =====\\n\")\n",
    "\n",
    "# Визначаємо, яку модель оптимізувати (регресія чи класифікація)\n",
    "if rf_metrics[2] > linear_metrics[2]:\n",
    "    print(\"Оптимізуємо Random Forest Regressor, оскільки він показав кращі результати.\")\n",
    "    # Параметри для пошуку\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Створення GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        rf_reg, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Навчання моделі з пошуком параметрів\n",
    "    grid_search.fit(X_reg_train, y_reg_train)\n",
    "    \n",
    "    # Найкращі параметри\n",
    "    print(\"\\nНайкращі параметри:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    # Оцінка оптимізованої моделі\n",
    "    best_rf_reg = grid_search.best_estimator_\n",
    "    y_reg_pred_best = best_rf_reg.predict(X_reg_test)\n",
    "    \n",
    "    print(\"\\nРезультати до оптимізації:\")\n",
    "    print(f\"MAE: {rf_metrics[0]:.4f}\")\n",
    "    print(f\"MSE: {rf_metrics[1]:.4f}\")\n",
    "    print(f\"R²: {rf_metrics[2]:.4f}\")\n",
    "    \n",
    "    print(\"\\nРезультати після оптимізації:\")\n",
    "    best_metrics = print_regression_metrics(y_reg_test, y_reg_pred_best, \"Оптимізований Random Forest Regressor\")\n",
    "    \n",
    "    # Порівняння результатів\n",
    "    print(\"\\nПокращення після оптимізації:\")\n",
    "    print(f\"MAE: {rf_metrics[0] - best_metrics[0]:.4f} ({(1 - best_metrics[0]/rf_metrics[0])*100:.2f}%)\")\n",
    "    print(f\"MSE: {rf_metrics[1] - best_metrics[1]:.4f} ({(1 - best_metrics[1]/rf_metrics[1])*100:.2f}%)\")\n",
    "    print(f\"R²: {best_metrics[2] - rf_metrics[2]:.4f} ({(best_metrics[2]/rf_metrics[2] - 1)*100:.2f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Оптимізуємо Random Forest Classifier, оскільки він показав кращі результати.\")\n",
    "    # Параметри для пошуку\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Створення GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        rf_cls, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Навчання моделі з пошуком параметрів\n",
    "    grid_search.fit(X_cls_train, y_cls_train)\n",
    "    \n",
    "    # Найкращі параметри\n",
    "    print(\"\\nНайкращі параметри:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    # Оцінка оптимізованої моделі\n",
    "    best_rf_cls = grid_search.best_estimator_\n",
    "    y_cls_pred_best = best_rf_cls.predict(X_cls_test)\n",
    "    \n",
    "    print(\"\\nРезультати до оптимізації:\")\n",
    "    print(f\"Accuracy: {rf_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\nРезультати після оптимізації:\")\n",
    "    best_acc = print_classification_metrics(y_cls_test, y_cls_pred_best, \"Оптимізований Random Forest Classifier\")\n",
    "    \n",
    "    # Порівняння результатів\n",
    "    print(\"\\nПокращення після оптимізації:\")\n",
    "    print(f\"Accuracy: {best_acc - rf_acc:.4f} ({(best_acc/rf_acc - 1)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nВисновки:\")\n",
    "print(\"1. Для регресійного аналізу Random Forest зазвичай показує кращі результати, ніж лінійна регресія,\")\n",
    "print(\"   оскільки може моделювати нелінійні залежності та взаємодії між ознаками.\")\n",
    "print(\"2. Для класифікації Random Forest також часто перевершує логістичну регресію,\")\n",
    "print(\"   особливо на складних даних з багатьма ознаками.\")\n",
    "print(\"3. Оптимізація гіперпараметрів дозволяє значно покращити результати моделей,\")\n",
    "print(\"   але вимагає більше обчислювальних ресурсів.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
